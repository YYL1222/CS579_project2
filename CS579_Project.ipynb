{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYMqk4G5xb11"
      },
      "source": [
        "# Pre Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP-NvqarmjNN"
      },
      "outputs": [],
      "source": [
        "# Import thing\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# sklearn for SVM & Tfidf Vectorization\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Data visulization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# check versions\n",
        "!python --version\n",
        "!nvidia-smi\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un6V5daomvyi"
      },
      "outputs": [],
      "source": [
        "# upload files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded:\n",
        "  print('User uploaded file\"{name}\" with length {length} bytes').format(name=fn, length=len(uploaded[fn]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3atEfxt3dQV"
      },
      "source": [
        "# Data Prepare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWz2IZhP3kV5"
      },
      "outputs": [],
      "source": [
        "# Read taining set \n",
        "dt_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/train.csv', index_col='id')\n",
        "dt_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/test.csv', index_col='id')\n",
        "dt_submit = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/sample_submission.csv', index_col='id')\n",
        "# del dt_test\n",
        "# del dt_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTgJGFZf4Ldd"
      },
      "outputs": [],
      "source": [
        "def preprocess(file_name='/content/drive/MyDrive/Colab Notebooks/cs579data/train.csv', index_col='id'):\n",
        "    data = pd.read_csv(file_name, index_col=index_col)\n",
        "\n",
        "    # remove error rows. cause some cases when tid1==tid2, the label is not 'agreed', it means the label is incorrect.\n",
        "    error_data = data[(data['tid1'] == data['tid2']) & (data['label'] != 'agreed')]\n",
        "    data = data.drop(error_data.index)\n",
        "\n",
        "    # get all real news\n",
        "    real_news = data[data['label'] == 'disagreed']['title2_en']\n",
        "\n",
        "    # get news with unknown label, set it to neutral_news\n",
        "    neutral_news = data[data['label'] == 'unrelated']['title2_en']\n",
        "\n",
        "    # get fake news from two part.\n",
        "    # part 1：all in 'tid1' \n",
        "    fake_news_1 = data[(data['tid1'] != data['tid2'])]['title1_en']\n",
        "    # part 2: all fake news in 'tid2'\n",
        "    fake_news_2 = data[(data['tid1'] != data['tid2']) & (data['label'] == 'agreed')]['title2_en']\n",
        "    fake_news_1.append(fake_news_2)\n",
        "\n",
        "    # save data\n",
        "    error_data.to_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/error.csv')\n",
        "    real_news.to_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/real.csv')\n",
        "    fake_news_1.to_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/fake.csv')\n",
        "    neutral_news.to_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/neutral.csv')\n",
        "preprocess()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnBPgnLo9p2S"
      },
      "source": [
        "## This part can read data that saved from previous data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-fJw4Eh5f6l"
      },
      "outputs": [],
      "source": [
        "dt_real = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/real.csv', index_col='id')\n",
        "dt_fake = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/fake.csv', index_col='id')\n",
        "dt_neutral = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/neutral.csv', index_col='id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-uJh3OW55T6"
      },
      "source": [
        "# NLTK Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsXscHf55_Sk"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "  \"\"\"\n",
        "    Preprocessing the text for each row.\n",
        "    Includes tokenization, removing stopwords, lemmatization and convert all the token to lowercase.\n",
        "  \"\"\"\n",
        "  # Tokenization\n",
        "  tokens = [word for sent in sent_tokenize(text) for word in word_tokenize(sent)]\n",
        "  stop = stopwords.words('english')\n",
        "  # Removing stopwords\n",
        "  tokens = [token for token in tokens if token not in stop]\n",
        "  tokens = [word for word in tokens if len(word) >= 3]\n",
        "  # Covert all tokens to lowercase\n",
        "  tokens = [word.lower() for word in tokens]\n",
        "  # Lemma\n",
        "  lmtzr = WordNetLemmatizer()\n",
        "  tokens = [lmtzr.lemmatize(word) for word in tokens]\n",
        "  preprocessed_text = ' '.join(tokens)\n",
        "  return preprocessed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJrpDXto7Jtl"
      },
      "outputs": [],
      "source": [
        "# preprocessed\n",
        "dt_real['preprocessed'] = dt_real.loc[:, ['title2_en']].applymap(preprocess_text)\n",
        "dt_neutral['preprocessed'] = dt_neutral.loc[:, ['title2_en']].applymap(preprocess_text)\n",
        "dt_fake['preprocessed'] = dt_fake.loc[:, ['title1_en']].applymap(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-Bp_upn7YF-"
      },
      "outputs": [],
      "source": [
        "# save, cause preprocess need much time\n",
        "dt_real.to_csv('real_processed.csv')\n",
        "dt_fake.to_csv('fake_processed.csv')\n",
        "dt_neutral.to_csv('neutral_processed.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok5Rs7r7AQFR"
      },
      "source": [
        "# Vectorization & split training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BkjsF3nAXmS"
      },
      "outputs": [],
      "source": [
        "# read preprocessed data\n",
        "dt_real = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/real_processed.csv', index_col='id')\n",
        "dt_fake = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/fake_processed.csv', index_col='id')\n",
        "dt_neutral = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/neutral_processed.csv', index_col='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuHqB9KPApUv"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, min_df=2, norm=None)\n",
        "real_vector = tfidf_vectorizer.fit_transform(dt_real['preprocessed'].values.astype('U'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p7_RND9I7Hp"
      },
      "source": [
        "# Data Preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rCb9dP3I99A"
      },
      "outputs": [],
      "source": [
        "dt_real['label'] = '0'\n",
        "dt_fake['label'] = '1'\n",
        "dt_neutral['label'] = '2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfkwVwBuLW-f"
      },
      "outputs": [],
      "source": [
        "print(dt_real.shape)\n",
        "print(dt_fake.shape)\n",
        "print(dt_neutral.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcMH01zSsmPk"
      },
      "outputs": [],
      "source": [
        "real_titles = dt_real.title2_en\n",
        "real_titles_ls = [text for text in real_titles]\n",
        "# print(alls)\n",
        "real_all_words = ' '.join(real_titles)\n",
        "wordcloud_real = WordCloud(background_color='white',\n",
        "    width= 800, height= 500,\n",
        "    max_font_size = 180,\n",
        "    collocations = False).generate(real_all_words)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(wordcloud_real, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMBpxGF-sohQ"
      },
      "outputs": [],
      "source": [
        "fake_titles = dt_fake.title1_en\n",
        "fake_titles_ls = [text for text in fake_titles]\n",
        "# print(alls)\n",
        "fake_all_words = ' '.join(fake_titles)\n",
        "wordcloud_fake = WordCloud(background_color='white',\n",
        "    width= 800, height= 500,\n",
        "    max_font_size = 180,\n",
        "    collocations = False).generate(fake_all_words)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(wordcloud_fake, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIBzbkqhsxz0"
      },
      "outputs": [],
      "source": [
        "neutral_titles = dt_neutral.title2_en\n",
        "neutral_titles_ls = [text for text in neutral_titles]\n",
        "# print(alls)\n",
        "neutral_all_words = ' '.join(neutral_titles)\n",
        "wordcloud_neutral = WordCloud(background_color='white',\n",
        "    width= 800, height= 500,\n",
        "    max_font_size = 180,\n",
        "    collocations = False).generate(neutral_all_words)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(wordcloud_neutral, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F1Z3hBz0NTc"
      },
      "source": [
        "# YiYi's Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcS35300uBqH"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPdDupY-EQY2"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "import time\n",
        "import torch\n",
        "import math\n",
        "import numpy\n",
        "from transformers import BertTokenizer\n",
        "from transformers import logging\n",
        "from IPython.display import clear_output\n",
        "from transformers import BertForMaskedLM\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from transformers import BertForSequenceClassification\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.sparse.construct import rand\n",
        "\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsbFHSpmuFoH"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfy7AJqyzU9x"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jx5MJCiz1Eb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqQ2vUB2B5pb"
      },
      "outputs": [],
      "source": [
        "def get_split(text):\n",
        "  \"\"\" only keep the first 150 words of a text. \"\"\"\n",
        "  return text[:150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_Gwp7Cmz_HJ"
      },
      "outputs": [],
      "source": [
        "# delete row with long title\n",
        "# Because long title will \n",
        "MAX_LENGTH = 150\n",
        "df_train = df_train[~(df_train.title1_en.apply(lambda x : len(x)) > MAX_LENGTH)]\n",
        "df_train = df_train[~(df_train.title2_en.apply(lambda x : len(x)) > MAX_LENGTH)]\n",
        "\n",
        "# 250 thousands training datas are too large to spend a lot of time \n",
        "# So I select 70 percents of datas to train the model\n",
        "SAMPLE_FRAC = 1.0\n",
        "df_train = df_train.sample(frac=SAMPLE_FRAC, random_state=9527)\n",
        "\n",
        "df_train = df_train.reset_index()\n",
        "df_train = df_train.loc[:, ['title1_en', 'title2_en', 'label']]\n",
        "\n",
        "# save processed training data to csv file\n",
        "df_train.to_csv(\"train.csv\", sep=\",\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGm_qK5k0B6T"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas\n",
        "df_len = len(df_train)\n",
        "#print(df_len)\n",
        "split = 0.7\n",
        "inde = math.floor(df_len * split)\n",
        "# split our data into train/validation sets in 70%/30%\n",
        "df_train_train = df_train.iloc[:inde, :] \n",
        "df_train_val = df_train.iloc[inde+1:, : ] \n",
        "print(len(df_train_train))\n",
        "print(len(df_train_val))\n",
        "df_train_train.to_csv(\"df_train_train.csv\", sep=\",\", index=False)\n",
        "df_train_val.to_csv(\"df_train_val.csv\", sep=\",\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5uOdw5l0EhT"
      },
      "outputs": [],
      "source": [
        "type(df_train_train)\n",
        "df_train_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaGoHmA0k7V4"
      },
      "source": [
        "### Visualize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdFW88K-g8Rb"
      },
      "outputs": [],
      "source": [
        "def vis_train_val_distribution(df_train_train, df_train_val):\n",
        "  labels = ['unrelated', 'agreed', 'disagreed']\n",
        "  train_set = []\n",
        "  valid_set = []\n",
        "  for label in labels:\n",
        "    train_set.append(df_train_train[df_train_train['label']==label]['label'].count())\n",
        "    valid_set.append(df_train_val[df_train_val['label']==label]['label'].count())\n",
        "\n",
        "  x = np.arange(len(labels))  # the label locations\n",
        "  width = 0.35  # the width of the bars\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  rects1 = ax.bar(x - width/2, train_set, width, label='TrainSet Distribution')\n",
        "  rects2 = ax.bar(x + width/2, valid_set, width, label='ValidSet Distribution')\n",
        "\n",
        "  ax.set_ylabel('Count')\n",
        "  ax.set_title('Train Valid Dataset Distribution')\n",
        "  ax.set_xticks(x, labels)\n",
        "  ax.legend()\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  fig1, ax = plt.subplots(1, 2)\n",
        "  ax[0].pie(train_set, labels=labels, autopct='%1.1f%%',\n",
        "          shadow=True, startangle=90)\n",
        "  ax[0].axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "  ax[0].set_title('Training Set')\n",
        "\n",
        "  ax[1].pie(valid_set, labels=labels, autopct='%1.1f%%',\n",
        "          shadow=True, startangle=90)\n",
        "  ax[1].axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "  ax[1].set_title('Validation Set')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwdBLDMIl_VN"
      },
      "outputs": [],
      "source": [
        "def generate_balance_data(df, max_num):\n",
        "  \"\"\"Create balanced data set\"\"\"\n",
        "  labels = ['unrelated', 'agreed', 'disagreed']  # as our project only have three labels\n",
        "  df_balanced = pd.DataFrame(columns=['title1_en', 'title2_en', 'label'])\n",
        "  for label in labels:\n",
        "    df_balanced = df_balanced.append(df[df['label']==label][0:max_num])\n",
        "  return df_balanced\n",
        "\n",
        "# df_train_train = generate_balance_data(df_train_train, 4000)\n",
        "df_train_val = generate_balance_data(df_train_val, 1000)\n",
        "df_train_train.to_csv(\"df_train_train.csv\", sep=\",\", index=False)\n",
        "df_train_val.to_csv(\"df_train_val.csv\", sep=\",\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB4J5T9xoifx"
      },
      "outputs": [],
      "source": [
        "vis_train_val_distribution(df_train_train, df_train_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGaSkBlzxJPy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbAsDdiX0Gfu"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.  \n",
        "    \n",
        "    device = torch.device('cuda')    \n",
        "\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkXZbV6qxM_q"
      },
      "source": [
        "### Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gwOTe-T0IQ-"
      },
      "outputs": [],
      "source": [
        "class fake_news(Dataset):\n",
        "    def __init__(self, mode, tokenizer):\n",
        "        assert mode in [\"df_train_train\", \"test\",\"df_train_val\"] \n",
        "        self.mode = mode\n",
        "        # generate train or test csv file\n",
        "        self.df = pd.read_csv(mode + \".csv\")\n",
        "        self.len = len(self.df)\n",
        "        self.label_map = {'agreed': 0, 'disagreed': 1, 'unrelated': 2}\n",
        "        self.tokenizer = tokenizer  \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode == \"test\":\n",
        "            title1_en, title2_en = self.df.iloc[idx, :2].values\n",
        "            label_tensor = None\n",
        "        else:\n",
        "            title1_en, title2_en, label = self.df.iloc[idx, :].values\n",
        "            label_id = self.label_map[label]\n",
        "            label_tensor = torch.tensor(label_id)\n",
        "\n",
        "        # First sentence ==> transfer to BERT tokens and add [SEP] to separate two sentences\n",
        "        word_pieces = [\"[CLS]\"]\n",
        "\n",
        "        tokens_1 = self.tokenizer.tokenize(title1_en)\n",
        "        word_pieces += tokens_1 + [\"[SEP]\"]\n",
        "        len_1 = len(word_pieces)\n",
        "\n",
        "        # Second sentence ==> transfer to BERT tokens and add [SEP]\n",
        "        tokens_2 = self.tokenizer.tokenize(title2_en)\n",
        "        word_pieces += tokens_2 + [\"[SEP]\"]\n",
        "        len_2 = len(word_pieces) - len_1\n",
        "\n",
        "        # transfer token to index\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "        tokens_tensor = torch.tensor(ids)\n",
        "\n",
        "        # [SEP] of first sentence set 0\n",
        "        # [SEP] of second sentence set 1\n",
        "        segments_tensor = torch.tensor([0] * len_1 + [1] * len_2,dtype=torch.long)     \n",
        "\n",
        "        return (tokens_tensor, segments_tensor, label_tensor)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbmOrThPxUpN"
      },
      "outputs": [],
      "source": [
        "def collate_fn(samples):\n",
        "    \n",
        "    tokens_tensors = [s[0] for s in samples]\n",
        "    segments_tensors = [s[1] for s in samples]\n",
        "    \n",
        "    # we have labels in testset and validation set\n",
        "    if samples[0][2] is not None:\n",
        "        label_ids = torch.stack([s[2] for s in samples])\n",
        "    else:\n",
        "        label_ids = None\n",
        "    \n",
        "\n",
        "    # make sure each tensor has same length\n",
        "    tokens_tensors = pad_sequence(tokens_tensors, batch_first=True)\n",
        "    segments_tensors = pad_sequence(segments_tensors, batch_first=True)\n",
        "\n",
        "    masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n",
        "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
        "\n",
        "    return tokens_tensors, segments_tensors, masks_tensors, label_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVIsyHGGxkIo"
      },
      "source": [
        "### Prediction Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWavFodZxmPW"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, dataloader, compute_acc=False): \n",
        "    predictions = None\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    i =0\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            # Use GPU to execute\n",
        "            if next(model.parameters()).is_cuda:\n",
        "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
        "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
        "            outputs = model(input_ids=tokens_tensors,token_type_ids=segments_tensors,attention_mask=masks_tensors)\n",
        "            OP = outputs[0]\n",
        "            _, pred = torch.max(OP.data, 1)\n",
        "          \n",
        "            # compute accuracy\n",
        "            if compute_acc:\n",
        "                labels = data[3]\n",
        "                total += labels.size(0)\n",
        "                correct += (pred == labels).sum().item()\n",
        "\n",
        "            # store the priduction of this batch\n",
        "            if predictions is None:\n",
        "                predictions = pred\n",
        "            else:\n",
        "                predictions = torch.cat((predictions, pred))\n",
        "    # We use this in training mode to know the accuracy of our model\n",
        "    if compute_acc:\n",
        "        acc = correct / total\n",
        "        return predictions, acc\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7qxKL7sxWpa"
      },
      "source": [
        "### Initial Training and Validation data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJNgHbem0KP-"
      },
      "outputs": [],
      "source": [
        "# initialize training data and validation data\n",
        "trainset = fake_news(\"df_train_train\", tokenizer=tokenizer)\n",
        "validset = fake_news(\"df_train_val\", tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDnDMbr0NVUm"
      },
      "outputs": [],
      "source": [
        "df_train_val['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yrn8tot70UnB"
      },
      "outputs": [],
      "source": [
        "# trainloader = DataLoader(trainset, batch_size=64,collate_fn=collate_fn)\n",
        "validloader = DataLoader(validset, batch_size=64,collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B--GaoJ70WW6"
      },
      "outputs": [],
      "source": [
        "PRETRAINED_MODEL_NAME = \"bert-base-cased\"\n",
        "NUM_LABELS = 3\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttqEx_1xxqD6"
      },
      "source": [
        "### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHI7g2jq0con"
      },
      "outputs": [],
      "source": [
        "# move our model over to the selected device\n",
        "model = model.to(device)\n",
        "print(\"device:\", device)\n",
        "# To know the accuracy before training\n",
        "#_, acc = get_predictions(model, validloader, compute_acc=True)\n",
        "#print(\"classification acc:\", acc)\n",
        "\n",
        "start = time.time()\n",
        "# activate training mode \n",
        "model.train()\n",
        "\n",
        "# initialize optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "pre_acc = 0.0\n",
        "epoch = 0\n",
        "while epoch <5:\n",
        "    running_loss = 0.0\n",
        "    for data in trainloader:\n",
        "        tokens_tensors, segments_tensors, \\\n",
        "        masks_tensors, labels = [t.to(device) for t in data]\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(input_ids=tokens_tensors,\n",
        "                token_type_ids=segments_tensors,\n",
        "                attention_mask=masks_tensors,\n",
        "                labels=labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # store the batch loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Use validation dataset to evaluate our model\n",
        "    _, acc = get_predictions(model, validloader, compute_acc=True)\n",
        "    # stop training when accuracy starts decreasing\n",
        "    if acc <= pre_acc - 0.05:\n",
        "      print(\"accuracy = %.4f is less than previous accuracy = %.4f - 0.2\" %(acc, pre_acc))\n",
        "      break\n",
        "    # record previous accuracy\n",
        "    pre_acc = acc\n",
        "    print('epoch %d ==> loss: %.3f, accuracy: %.4f' %(epoch + 1, running_loss, acc))\n",
        "    epoch += 1\n",
        "\n",
        "print(\"The time used to execute this is given below\")\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(end - start)\n",
        "torch.save(model, '/content/drive/MyDrive/Colab Notebooks/cs579data/9000train.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzLUfOhh9Kg6"
      },
      "outputs": [],
      "source": [
        "# model = torch.load('/content/drive/MyDrive/Colab Notebooks/cs579data/full_train.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9l1HRQThutA"
      },
      "outputs": [],
      "source": [
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBlvxylPx3JA"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDDMwovHx8E0"
      },
      "source": [
        "#### Prepare test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AklhRlR0zUZ"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 200\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/test.csv')\n",
        "print(len(df_test))\n",
        "# df_test = df_test[~(df_test.title1_en.apply(lambda x : len(x)) > MAX_LENGTH)]\n",
        "# df_test = df_test[~(df_test.title2_en.apply(lambda x : len(x)) > MAX_LENGTH)]\n",
        "df_test['title1_en'] = df_test['title1_en'].apply(get_split)\n",
        "df_test['title2_en'] = df_test['title2_en'].apply(get_split)\n",
        "df_test = df_test.reset_index()\n",
        "df_test = df_test.loc[:, ['title1_en', 'title2_en','id']]\n",
        "print(len(df_test))\n",
        "df_test.to_csv(\"test.csv\", sep=\",\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaaBDWyshj_8"
      },
      "outputs": [],
      "source": [
        "# keep a copy of original df_train_val dataset, for test each experiment\n",
        "df_train_val.to_csv(\"df_train_val_test.csv\", sep=\",\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jra6qo58YgOn"
      },
      "outputs": [],
      "source": [
        "def valid_model():\n",
        "  df_train_val = pd.read_csv(\"df_train_val_test.csv\")\n",
        "  df_train_val = generate_balance_data(df_train_val, 1000)\n",
        "  df_train_val.to_csv(\"df_train_val.csv\", sep=\",\", index=False)\n",
        "  print(df_train_val['label'].value_counts())\n",
        "  # initialize validation data\n",
        "  validset = fake_news(\"df_train_val\", tokenizer=tokenizer)\n",
        "  \n",
        "  validloader = DataLoader(validset, batch_size=64,collate_fn=collate_fn)\n",
        "  _, acc = get_predictions(model, validloader, compute_acc=True)\n",
        "  print(\"classification acc:\", acc)\n",
        "valid_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_ezOZgiyBuw"
      },
      "source": [
        "#### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BfQTewt0042"
      },
      "outputs": [],
      "source": [
        "testset = fake_news(\"test\", tokenizer=tokenizer)\n",
        "testloader = DataLoader(testset, batch_size=50,collate_fn=collate_fn)\n",
        "\n",
        "predictions = get_predictions(model, testloader)\n",
        "\n",
        "# transform the label to the words we can understand\n",
        "index_map = {v: k for k, v in testset.label_map.items()}\n",
        "\n",
        "# produce the result file\n",
        "df = pd.DataFrame({\"label\": predictions.tolist()})\n",
        "df['label'] = df.label.apply(lambda x: index_map[x])\n",
        "df_pred = pd.concat([testset.df.loc[:, [\"id\"]], df.loc[:, 'label']], axis=1)\n",
        "df_pred.to_csv('/content/drive/MyDrive/Colab Notebooks/cs579data/“submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmvMzv3OHzLY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "CS579 Project",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
